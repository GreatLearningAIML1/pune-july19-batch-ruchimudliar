{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"R6_Internal_Lab_UpdatedTF2_Prices_Iris.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"84Q8JfvaeZZ6"},"source":["## Linear Classifier in TensorFlow \n","Using Low Level API in Eager Execution mode"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"sb7Epo0VOB58"},"source":["### Load tensorflow"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"fHpCNRv1OB5-","colab":{}},"source":["import tensorflow as tf\n","\n","import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Mjtb-EMcm5K0","colab":{}},"source":["\n","#Enable Eager Execution if using tensflow version < 2.0\n","#From tensorflow v2.0 onwards, Eager Execution will be enabled by default\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"DxJDmJqqOB6K"},"source":["### Collect Data"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"FhllFLyKOB6N","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"24853174-d494-4d64-9f7a-f04bb6dffbac","executionInfo":{"status":"ok","timestamp":1575201470226,"user_tz":-330,"elapsed":981,"user":{"displayName":"kavyal jani","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBqIizcIpG2a-X_XfAmlPlYnzvTEj8gGdJbKNzlzw=s64","userId":"03855859549810352770"}}},"source":["from google.colab import drive\n","#drive.mount('/gdrive',force_remount=True)\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":242,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"KiObW4V4SIOz","colab":{}},"source":["import pandas as pd\n","import os"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"J2iBqSyWt4wg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"05778654-5ec1-4e9f-8fea-efce3681509e","executionInfo":{"status":"ok","timestamp":1575201480435,"user_tz":-330,"elapsed":9472,"user":{"displayName":"kavyal jani","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBqIizcIpG2a-X_XfAmlPlYnzvTEj8gGdJbKNzlzw=s64","userId":"03855859549810352770"}}},"source":["#data = pd.read_csv('/drive//sample_data')\n","print(os.getcwd())\n","!ls"],"execution_count":244,"outputs":[{"output_type":"stream","text":["/content\n","drive  sample_data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"B4yQKMiJOB6R","colab":{}},"source":["data = pd.read_csv(\"/content/drive/My Drive/internalLab/prices.csv\", delimiter=\",\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"fgkX6SEqOB6W"},"source":["### Check all columns in the dataset"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"7K8pWsNQOB6X","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"f628948a-e35c-49da-c6d1-b650e66cb04f","executionInfo":{"status":"ok","timestamp":1575201481795,"user_tz":-330,"elapsed":9124,"user":{"displayName":"kavyal jani","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBqIizcIpG2a-X_XfAmlPlYnzvTEj8gGdJbKNzlzw=s64","userId":"03855859549810352770"}}},"source":["data.columns"],"execution_count":246,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index([u'date', u'symbol', u'open', u'close', u'low', u'high', u'volume'], dtype='object')"]},"metadata":{"tags":[]},"execution_count":246}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"7dU6X7MpOB6c"},"source":["### Drop columns `date` and  `symbol`"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"lh_6spSKOB6e","colab":{}},"source":["data.drop(['date','symbol'],axis=1,inplace=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"xlwbUgTwOB6i","outputId":"617a38fb-f30d-4d71-b580-95c752730211","colab":{"base_uri":"https://localhost:8080/","height":202},"executionInfo":{"status":"ok","timestamp":1575201481802,"user_tz":-330,"elapsed":7826,"user":{"displayName":"kavyal jani","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBqIizcIpG2a-X_XfAmlPlYnzvTEj8gGdJbKNzlzw=s64","userId":"03855859549810352770"}}},"source":["data.head()"],"execution_count":248,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>open</th>\n","      <th>close</th>\n","      <th>low</th>\n","      <th>high</th>\n","      <th>volume</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>123.430000</td>\n","      <td>125.839996</td>\n","      <td>122.309998</td>\n","      <td>126.250000</td>\n","      <td>2163600.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>125.239998</td>\n","      <td>119.980003</td>\n","      <td>119.940002</td>\n","      <td>125.540001</td>\n","      <td>2386400.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>116.379997</td>\n","      <td>114.949997</td>\n","      <td>114.930000</td>\n","      <td>119.739998</td>\n","      <td>2489500.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>115.480003</td>\n","      <td>116.620003</td>\n","      <td>113.500000</td>\n","      <td>117.440002</td>\n","      <td>2006300.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>117.010002</td>\n","      <td>114.970001</td>\n","      <td>114.089996</td>\n","      <td>117.330002</td>\n","      <td>1408600.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         open       close         low        high     volume\n","0  123.430000  125.839996  122.309998  126.250000  2163600.0\n","1  125.239998  119.980003  119.940002  125.540001  2386400.0\n","2  116.379997  114.949997  114.930000  119.739998  2489500.0\n","3  115.480003  116.620003  113.500000  117.440002  2006300.0\n","4  117.010002  114.970001  114.089996  117.330002  1408600.0"]},"metadata":{"tags":[]},"execution_count":248}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"3DBv3WWYOB6q"},"source":["### Consider only first 1000 rows in the dataset for building feature set and target set\n","Target 'Volume' has very high values. Divide 'Volume' by 1000,000"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Z_hG9rGBOB6s","colab":{}},"source":["data['volume']=data.iloc[0:1001,4]/1000000"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MlOi-DW8z2-q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":202},"outputId":"90f3bf30-a173-47b8-cd32-2489a0e8d433","executionInfo":{"status":"ok","timestamp":1575201488218,"user_tz":-330,"elapsed":1592,"user":{"displayName":"kavyal jani","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBqIizcIpG2a-X_XfAmlPlYnzvTEj8gGdJbKNzlzw=s64","userId":"03855859549810352770"}}},"source":["data.head()"],"execution_count":250,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>open</th>\n","      <th>close</th>\n","      <th>low</th>\n","      <th>high</th>\n","      <th>volume</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>123.430000</td>\n","      <td>125.839996</td>\n","      <td>122.309998</td>\n","      <td>126.250000</td>\n","      <td>2.1636</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>125.239998</td>\n","      <td>119.980003</td>\n","      <td>119.940002</td>\n","      <td>125.540001</td>\n","      <td>2.3864</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>116.379997</td>\n","      <td>114.949997</td>\n","      <td>114.930000</td>\n","      <td>119.739998</td>\n","      <td>2.4895</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>115.480003</td>\n","      <td>116.620003</td>\n","      <td>113.500000</td>\n","      <td>117.440002</td>\n","      <td>2.0063</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>117.010002</td>\n","      <td>114.970001</td>\n","      <td>114.089996</td>\n","      <td>117.330002</td>\n","      <td>1.4086</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         open       close         low        high  volume\n","0  123.430000  125.839996  122.309998  126.250000  2.1636\n","1  125.239998  119.980003  119.940002  125.540001  2.3864\n","2  116.379997  114.949997  114.930000  119.739998  2.4895\n","3  115.480003  116.620003  113.500000  117.440002  2.0063\n","4  117.010002  114.970001  114.089996  117.330002  1.4086"]},"metadata":{"tags":[]},"execution_count":250}]},{"cell_type":"code","metadata":{"id":"L0kMfQCIzfjj","colab_type":"code","colab":{}},"source":["data_new=data.iloc[0:1000,:]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"28nNResU0mhH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"97ed4683-e45b-4abe-d9b5-32a58da371e1","executionInfo":{"status":"ok","timestamp":1575201497075,"user_tz":-330,"elapsed":806,"user":{"displayName":"kavyal jani","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBqIizcIpG2a-X_XfAmlPlYnzvTEj8gGdJbKNzlzw=s64","userId":"03855859549810352770"}}},"source":["data_new.shape"],"execution_count":252,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1000, 5)"]},"metadata":{"tags":[]},"execution_count":252}]},{"cell_type":"code","metadata":{"id":"OWhY-DjD1WCx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":202},"outputId":"341623f0-0402-4103-b1ad-3a58db76f0b3","executionInfo":{"status":"ok","timestamp":1575201498431,"user_tz":-330,"elapsed":1598,"user":{"displayName":"kavyal jani","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBqIizcIpG2a-X_XfAmlPlYnzvTEj8gGdJbKNzlzw=s64","userId":"03855859549810352770"}}},"source":["data_new.head()"],"execution_count":253,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>open</th>\n","      <th>close</th>\n","      <th>low</th>\n","      <th>high</th>\n","      <th>volume</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>123.430000</td>\n","      <td>125.839996</td>\n","      <td>122.309998</td>\n","      <td>126.250000</td>\n","      <td>2.1636</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>125.239998</td>\n","      <td>119.980003</td>\n","      <td>119.940002</td>\n","      <td>125.540001</td>\n","      <td>2.3864</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>116.379997</td>\n","      <td>114.949997</td>\n","      <td>114.930000</td>\n","      <td>119.739998</td>\n","      <td>2.4895</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>115.480003</td>\n","      <td>116.620003</td>\n","      <td>113.500000</td>\n","      <td>117.440002</td>\n","      <td>2.0063</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>117.010002</td>\n","      <td>114.970001</td>\n","      <td>114.089996</td>\n","      <td>117.330002</td>\n","      <td>1.4086</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         open       close         low        high  volume\n","0  123.430000  125.839996  122.309998  126.250000  2.1636\n","1  125.239998  119.980003  119.940002  125.540001  2.3864\n","2  116.379997  114.949997  114.930000  119.739998  2.4895\n","3  115.480003  116.620003  113.500000  117.440002  2.0063\n","4  117.010002  114.970001  114.089996  117.330002  1.4086"]},"metadata":{"tags":[]},"execution_count":253}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"M3UaApqYOB6x"},"source":["### Divide the data into train and test sets"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"4LE4U8lTdQJq","colab":{}},"source":["from sklearn.model_selection import train_test_split"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9fkF-p3Q0Jy-","colab_type":"code","colab":{}},"source":["X = data_new.iloc[:,0:4]\n","Y = data_new.iloc[:,4]\n","train_x,test_x,train_y,test_y=train_test_split(X,Y,test_size=.30,random_state=2)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"oYK-aUuLbrz2"},"source":["#### Convert Training and Test Data to numpy float32 arrays\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Ao-S0tQGcncz","colab":{}},"source":["train_x =np.array(train_x).astype('float32')\n","test_x = np.array(test_x).astype('float32')\n","train_y =np.array(train_y).astype('float32')\n","test_y = np.array(test_y).astype('float32')\n","\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"im1ZegbDdKgv"},"source":["### Normalize the data\n","You can use Normalizer from sklearn.preprocessing"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"2EkKAy7fOB6y","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"7fc3703b-b654-4a0a-dac2-8b7813dda69d","executionInfo":{"status":"error","timestamp":1575201513747,"user_tz":-330,"elapsed":907,"user":{"displayName":"kavyal jani","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBqIizcIpG2a-X_XfAmlPlYnzvTEj8gGdJbKNzlzw=s64","userId":"03855859549810352770"}}},"source":["from sklearn.preprocessing import Normalizer\n","transformer = Normalizer()\n","train_x = transformer.fit_transform(train_x)\n","test_x = transformer.transform(test_x)\n","train_y=transformer.transform(train_y)"],"execution_count":257,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m\u001b[0m","\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)","\u001b[0;32m<ipython-input-257-88b2534ddf92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.pyc\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, y, copy)\u001b[0m\n\u001b[1;32m   1704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1705\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1706\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1707\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    550\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[7.151000e-01 4.550800e+00 7.499000e-01 2.465900e+00 5.147000e-01\n 3.293000e-01 4.277900e+00 2.856000e+00 4.545400e+00 1.426600e+00\n 2.521200e+01 3.252400e+00 1.964100e+00 3.959400e+00 9.246000e-01\n 2.489500e+00 3.624100e+00 1.197120e+01 1.637000e+01 7.449000e-01\n 4.564300e+00 1.731300e+01 2.652000e+00 2.849400e+00 3.945000e-01\n 5.421900e+00 1.975600e+00 7.165000e-01 1.559430e+01 1.120200e+00\n 3.227300e+00 1.793200e+00 8.385500e+00 2.971500e+00 1.526800e+00\n 6.109400e+00 8.980000e-01 5.985370e+01 3.450400e+00 9.280400e+00\n 5.156400e+00 4.406600e+00 3.637000e+00 1.483400e+00 5.405000e-01\n 6.819000e-01 1.197240e+01 1.541000e+00 7.125000e-01 1.066340e+01\n 1.653910e+01 1.357340e+01 5.341000e-01 6.686170e+01 2.946600e+00\n 5.875500e+00 1.524500e+00 7.389200e+00 8.847000e-01 2.033000e+00\n 2.701000e+00 2.206600e+00 1.051400e+00 3.107000e-01 7.134000e-01\n 1.490160e+01 4.432000e-01 6.944100e+00 2.353000e+00 6.804000e-01\n 2.904000e+00 7.020200e+00 3.908400e+00 1.863800e+00 1.270070e+01\n 4.011600e+00 2.497100e+00 5.222400e+00 2.081200e+00 3.716000e+00\n 9.321000e+00 1.840900e+00 9.215000e-01 1.067310e+01 3.299500e+00\n 1.835200e+00 8.594200e+00 6.624000e-01 3.332500e+00 3.120000e-01\n 1.046000e+00 6.813000e-01 9.616700e+00 1.982400e+00 2.539600e+00\n 4.103000e-01 1.278200e+00 1.455600e+00 8.229000e-01 1.199700e+00\n 7.953300e+00 5.799100e+00 1.414100e+00 8.632000e-01 2.460200e+00\n 2.006300e+00 1.795200e+00 3.246000e-01 8.440000e-01 2.947000e-01\n 9.204000e-01 3.139000e-01 9.206100e+00 6.920000e-01 4.009700e+00\n 8.190000e-01 5.372700e+00 1.898970e+01 3.811400e+00 4.048000e-01\n 5.158000e-01 3.324500e+00 4.600000e-01 4.170000e-01 2.356500e+00\n 5.352000e-01 1.650400e+00 3.828900e+00 1.910400e+00 3.802000e-01\n 2.670400e+00 8.844000e-01 2.627800e+00 1.332800e+00 3.729300e+00\n 4.225500e+00 2.413400e+00 5.245000e-01 2.362000e+00 7.283000e-01\n 6.979200e+00 8.867800e+00 1.545450e+01 3.840910e+01 2.493300e+00\n 2.707500e+00 1.064120e+01 1.162100e+00 5.945000e-01 9.277000e-01\n 4.252000e-01 2.071000e+00 4.076600e+00 4.573600e+00 5.619000e-01\n 8.574000e-01 2.136200e+00 2.708800e+00 2.642400e+00 1.219950e+01\n 6.568600e+00 1.048000e+00 5.465000e-01 8.266000e-01 4.622000e-01\n 5.018000e-01 3.280200e+00 3.657000e-01 1.854400e+00 2.317240e+01\n 7.651000e-01 1.388080e+01 4.911500e+00 4.141000e-01 1.666080e+01\n 2.431800e+00 4.083000e-01 9.676000e-01 1.049400e+00 2.898800e+00\n 2.176100e+00 3.508400e+00 6.300000e-01 1.234200e+00 1.829710e+01\n 1.377600e+00 1.422200e+00 3.215100e+00 4.923600e+00 6.941000e-01\n 6.155300e+00 2.166000e-01 8.834000e-01 1.206800e+00 7.114000e-01\n 5.757000e-01 5.339000e-01 5.130400e+00 8.833800e+00 5.947000e-01\n 5.277400e+00 5.592000e-01 1.129300e+00 8.488000e-01 5.342100e+00\n 3.059400e+00 3.473200e+00 5.532000e-01 2.679500e+01 7.806000e-01\n 3.680300e+00 1.001300e+00 1.306900e+00 1.347270e+01 2.735200e+00\n 1.472000e+00 3.619000e-01 2.236000e-01 2.161800e+00 3.630600e+00\n 1.185100e+00 6.031900e+00 6.146000e-01 4.236000e-01 2.631000e+00\n 1.931500e+00 2.633000e-01 5.707000e-01 3.787000e-01 8.769000e-01\n 2.227600e+00 4.832000e+00 7.943000e-01 1.098400e+00 1.935200e+00\n 5.262000e-01 7.439200e+00 4.788000e-01 4.101000e-01 1.725200e+00\n 2.668310e+01 9.185600e+00 5.027000e-01 5.982000e-01 7.543000e-01\n 1.693300e+01 1.200500e+00 1.151210e+01 6.555000e-01 7.225000e-01\n 1.946000e+00 2.464500e+00 4.659000e-01 3.546050e+01 2.344800e+00\n 1.574200e+00 3.982800e+00 9.376000e-01 5.604300e+00 6.588000e-01\n 1.616100e+00 1.689300e+00 5.123000e-01 6.593000e-01 3.858000e-01\n 1.098000e+00 4.780090e+01 1.734900e+00 9.931300e+00 3.581000e-01\n 5.631000e-01 3.258700e+00 1.425500e+00 7.552600e+00 4.626000e-01\n 2.965200e+00 2.613000e+00 4.442000e-01 6.997800e+00 4.597600e+00\n 3.437400e+00 1.856900e+00 3.043700e+00 5.423000e-01 1.241400e+00\n 3.252000e+00 4.645000e-01 1.196900e+00 6.172000e+00 9.292000e-01\n 3.829000e-01 5.202600e+00 5.119300e+00 3.252000e-01 3.239900e+00\n 6.668600e+00 5.103000e-01 5.320100e+00 7.517100e+00 1.371800e+00\n 5.441000e+00 1.936000e+00 2.000510e+01 2.210900e+00 9.283000e-01\n 1.122200e+00 1.636000e+00 2.415600e+00 7.672000e-01 7.097000e-01\n 2.997000e+00 1.082900e+01 1.288600e+00 4.284000e+00 4.899400e+00\n 4.072100e+00 1.759600e+00 6.585900e+00 2.228100e+00 7.932000e-01\n 9.571000e-01 6.479200e+00 6.010500e+00 1.291600e+00 1.030770e+01\n 3.272900e+00 1.036930e+01 5.403000e-01 3.193000e+00 1.634900e+00\n 7.844500e+00 7.499000e-01 3.276600e+00 9.224000e-01 1.128200e+00\n 1.323500e+00 1.446400e+00 3.529000e-01 3.385100e+00 7.667000e-01\n 1.504762e+02 2.247700e+00 2.827000e+00 3.001500e+00 6.076000e-01\n 1.658740e+01 4.294000e-01 8.281000e-01 3.380500e+00 2.251160e+01\n 1.157160e+01 6.297000e-01 2.102700e+00 5.625400e+00 2.674000e+00\n 6.325000e-01 1.234324e+02 1.233000e+00 9.837300e+00 6.433800e+00\n 9.510000e-02 6.705800e+00 4.925700e+00 1.651270e+01 1.504500e+00\n 8.564000e-01 2.680000e-01 5.263000e-01 6.085580e+01 1.093600e+00\n 3.023700e+00 4.621000e-01 9.496000e-01 2.352700e+00 2.127200e+00\n 2.060800e+00 6.767000e-01 1.299300e+00 3.974600e+00 1.541800e+00\n 2.485100e+00 8.415000e-01 2.219590e+01 3.687800e+00 2.522700e+00\n 1.018900e+00 1.068500e+00 2.232400e+00 1.146750e+01 3.472500e+00\n 5.746000e-01 7.737000e-01 2.750500e+00 3.872300e+00 9.443000e-01\n 4.227100e+00 8.735000e-01 8.171000e+00 4.767000e+00 2.008500e+00\n 5.911000e-01 3.965300e+00 5.910000e-01 4.112000e-01 8.225000e-01\n 1.173300e+00 2.238700e+00 4.619400e+00 1.467680e+01 6.515000e-01\n 1.524100e+00 5.800000e-01 6.932000e-01 4.874200e+00 3.693000e-01\n 8.785900e+00 6.186700e+00 3.221500e+00 7.002000e-01 1.159600e+00\n 6.135000e-01 3.100900e+00 8.989000e-01 1.572200e+00 9.625000e+00\n 1.056210e+01 4.967000e-01 3.386900e+00 1.301200e+00 3.433800e+00\n 5.367000e-01 2.660500e+00 2.805400e+00 1.701700e+00 1.030800e+00\n 1.873800e+00 4.592000e-01 3.684600e+00 5.993700e+00 1.304800e+00\n 1.387040e+01 2.122660e+01 5.208600e+01 1.988000e-01 1.991600e+00\n 7.022000e-01 7.750900e+00 6.407000e-01 7.129000e-01 1.153830e+01\n 2.014200e+00 4.510400e+00 2.363100e+00 3.429000e-01 8.997000e-01\n 1.697360e+01 1.062400e+00 4.450000e+00 1.141850e+01 7.965000e-01\n 1.338000e+00 1.009500e+00 8.184000e-01 3.139000e-01 3.350600e+00\n 8.391000e+00 2.476800e+00 5.122000e-01 3.930100e+00 1.861510e+01\n 9.107000e-01 1.129600e+00 5.503000e-01 6.313200e+00 3.007400e+00\n 4.186000e+00 1.502200e+00 5.095000e-01 5.036000e-01 5.697200e+00\n 1.051100e+00 4.599000e-01 1.438400e+00 7.766400e+00 4.986100e+00\n 2.536000e+00 9.308000e-01 1.523500e+00 4.168000e-01 8.167000e-01\n 6.455060e+01 2.133200e+00 3.441270e+01 5.385900e+00 6.894300e+00\n 1.131400e+00 1.808240e+01 2.387000e-01 1.542910e+01 7.182800e+00\n 1.049700e+00 4.502200e+00 3.223400e+00 1.680700e+00 1.261400e+00\n 7.061000e-01 1.878380e+01 2.824700e+00 2.095213e+02 1.793700e+00\n 6.017600e+00 5.996200e+00 6.883000e+00 1.897000e+00 1.093700e+00\n 7.611000e-01 9.097500e+00 4.514800e+00 6.067100e+00 9.555900e+00\n 1.832400e+00 7.141000e-01 9.563000e-01 2.728100e+00 1.990400e+01\n 5.231900e+00 2.654000e+00 8.226000e-01 1.290600e+01 4.135000e-01\n 4.444300e+00 1.169700e+00 2.749000e+00 5.902000e-01 3.025000e-01\n 1.301200e+00 5.621000e-01 9.506200e+00 1.011700e+00 2.575800e+00\n 6.397000e-01 5.249500e+00 1.341000e+00 3.699000e-01 2.459700e+00\n 5.548000e-01 1.884500e+00 1.402360e+01 5.206100e+00 2.035300e+00\n 1.412800e+00 1.457020e+01 5.572000e-01 2.533400e+00 2.242100e+00\n 3.731300e+00 2.163600e+00 1.104860e+01 1.224700e+00 3.011000e-01\n 1.744900e+00 1.461900e+00 2.347600e+00 1.865200e+00 8.851900e+00\n 7.496000e-01 5.235770e+01 1.319500e+00 9.200000e-01 1.553600e+00\n 1.257500e+01 2.173700e+00 5.780000e-01 2.962300e+00 6.710900e+00\n 3.553300e+00 1.932400e+00 4.034900e+00 8.445000e-01 3.355000e+00\n 4.008800e+00 7.942400e+00 1.859700e+00 5.834000e-01 4.254200e+00\n 1.089100e+00 3.989000e-01 1.008450e+01 7.795500e+00 3.711400e+00\n 4.180600e+00 1.175480e+01 8.727000e+00 7.614000e-01 2.315000e+00\n 5.143000e-01 7.347000e-01 2.018000e+01 2.670300e+00 4.152100e+00\n 7.099000e+00 7.982000e-01 6.948000e-01 5.012300e+00 9.198000e-01\n 2.836000e-01 2.705400e+00 1.302400e+00 1.433230e+01 4.473000e-01\n 1.774650e+01 3.738000e-01 7.000000e-01 6.121300e+00 2.078820e+01\n 1.271880e+01 3.880200e+00 2.869260e+01 1.723960e+01 6.408000e-01\n 1.597300e+00 3.905600e+00 1.793700e+00 1.843600e+00 1.448250e+01\n 5.734800e+00 5.275000e+00 9.190800e+00 2.922100e+00 6.205100e+00\n 1.136610e+01 1.646900e+00 7.742000e-01 2.220100e+01 7.507000e-01\n 7.804000e+00 1.517320e+01 1.228200e+00 1.656200e+00 3.715280e+01\n 6.707990e+01 2.913660e+01 3.039700e+00 1.336700e+00 1.683700e+00\n 4.457000e-01 4.067930e+01 1.442840e+01 5.671000e-01 8.093000e-01\n 1.168200e+00 1.967200e+00 4.890300e+00 1.652600e+00 1.244300e+00\n 7.952000e-01 7.367000e-01 4.812000e-01 4.278700e+00 1.808452e+02\n 2.555900e+00 5.948000e-01 4.553000e+00 7.325600e+00 2.455900e+00\n 2.981200e+00 1.670800e+00 7.511700e+00 3.611900e+00 2.068100e+00\n 1.607300e+00 1.157100e+00 6.841400e+00 7.023400e+00 4.415000e-01\n 6.819000e-01 6.104100e+00 5.296800e+00 5.771300e+00 8.584000e-01\n 4.480000e-01 3.008800e+00 3.407100e+00 1.059370e+01 4.951000e-01\n 7.108800e+00 9.610000e-01 2.792600e+00 1.198500e+00 5.894200e+00\n 2.228600e+00 5.765200e+00 6.953000e-01 7.948000e-01 8.292000e-01\n 4.900000e-01 3.470900e+00 6.263800e+00 2.035200e+00 4.873000e-01].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."]}]},{"cell_type":"code","metadata":{"id":"SMtbtPobAdNi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"722114c2-6c27-4d71-bec9-8519ffdb0a4a","executionInfo":{"status":"ok","timestamp":1575201583348,"user_tz":-330,"elapsed":1329,"user":{"displayName":"kavyal jani","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBqIizcIpG2a-X_XfAmlPlYnzvTEj8gGdJbKNzlzw=s64","userId":"03855859549810352770"}}},"source":["train_y.reshape(1, -1)"],"execution_count":260,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[7.151000e-01, 4.550800e+00, 7.499000e-01, 2.465900e+00,\n","        5.147000e-01, 3.293000e-01, 4.277900e+00, 2.856000e+00,\n","        4.545400e+00, 1.426600e+00, 2.521200e+01, 3.252400e+00,\n","        1.964100e+00, 3.959400e+00, 9.246000e-01, 2.489500e+00,\n","        3.624100e+00, 1.197120e+01, 1.637000e+01, 7.449000e-01,\n","        4.564300e+00, 1.731300e+01, 2.652000e+00, 2.849400e+00,\n","        3.945000e-01, 5.421900e+00, 1.975600e+00, 7.165000e-01,\n","        1.559430e+01, 1.120200e+00, 3.227300e+00, 1.793200e+00,\n","        8.385500e+00, 2.971500e+00, 1.526800e+00, 6.109400e+00,\n","        8.980000e-01, 5.985370e+01, 3.450400e+00, 9.280400e+00,\n","        5.156400e+00, 4.406600e+00, 3.637000e+00, 1.483400e+00,\n","        5.405000e-01, 6.819000e-01, 1.197240e+01, 1.541000e+00,\n","        7.125000e-01, 1.066340e+01, 1.653910e+01, 1.357340e+01,\n","        5.341000e-01, 6.686170e+01, 2.946600e+00, 5.875500e+00,\n","        1.524500e+00, 7.389200e+00, 8.847000e-01, 2.033000e+00,\n","        2.701000e+00, 2.206600e+00, 1.051400e+00, 3.107000e-01,\n","        7.134000e-01, 1.490160e+01, 4.432000e-01, 6.944100e+00,\n","        2.353000e+00, 6.804000e-01, 2.904000e+00, 7.020200e+00,\n","        3.908400e+00, 1.863800e+00, 1.270070e+01, 4.011600e+00,\n","        2.497100e+00, 5.222400e+00, 2.081200e+00, 3.716000e+00,\n","        9.321000e+00, 1.840900e+00, 9.215000e-01, 1.067310e+01,\n","        3.299500e+00, 1.835200e+00, 8.594200e+00, 6.624000e-01,\n","        3.332500e+00, 3.120000e-01, 1.046000e+00, 6.813000e-01,\n","        9.616700e+00, 1.982400e+00, 2.539600e+00, 4.103000e-01,\n","        1.278200e+00, 1.455600e+00, 8.229000e-01, 1.199700e+00,\n","        7.953300e+00, 5.799100e+00, 1.414100e+00, 8.632000e-01,\n","        2.460200e+00, 2.006300e+00, 1.795200e+00, 3.246000e-01,\n","        8.440000e-01, 2.947000e-01, 9.204000e-01, 3.139000e-01,\n","        9.206100e+00, 6.920000e-01, 4.009700e+00, 8.190000e-01,\n","        5.372700e+00, 1.898970e+01, 3.811400e+00, 4.048000e-01,\n","        5.158000e-01, 3.324500e+00, 4.600000e-01, 4.170000e-01,\n","        2.356500e+00, 5.352000e-01, 1.650400e+00, 3.828900e+00,\n","        1.910400e+00, 3.802000e-01, 2.670400e+00, 8.844000e-01,\n","        2.627800e+00, 1.332800e+00, 3.729300e+00, 4.225500e+00,\n","        2.413400e+00, 5.245000e-01, 2.362000e+00, 7.283000e-01,\n","        6.979200e+00, 8.867800e+00, 1.545450e+01, 3.840910e+01,\n","        2.493300e+00, 2.707500e+00, 1.064120e+01, 1.162100e+00,\n","        5.945000e-01, 9.277000e-01, 4.252000e-01, 2.071000e+00,\n","        4.076600e+00, 4.573600e+00, 5.619000e-01, 8.574000e-01,\n","        2.136200e+00, 2.708800e+00, 2.642400e+00, 1.219950e+01,\n","        6.568600e+00, 1.048000e+00, 5.465000e-01, 8.266000e-01,\n","        4.622000e-01, 5.018000e-01, 3.280200e+00, 3.657000e-01,\n","        1.854400e+00, 2.317240e+01, 7.651000e-01, 1.388080e+01,\n","        4.911500e+00, 4.141000e-01, 1.666080e+01, 2.431800e+00,\n","        4.083000e-01, 9.676000e-01, 1.049400e+00, 2.898800e+00,\n","        2.176100e+00, 3.508400e+00, 6.300000e-01, 1.234200e+00,\n","        1.829710e+01, 1.377600e+00, 1.422200e+00, 3.215100e+00,\n","        4.923600e+00, 6.941000e-01, 6.155300e+00, 2.166000e-01,\n","        8.834000e-01, 1.206800e+00, 7.114000e-01, 5.757000e-01,\n","        5.339000e-01, 5.130400e+00, 8.833800e+00, 5.947000e-01,\n","        5.277400e+00, 5.592000e-01, 1.129300e+00, 8.488000e-01,\n","        5.342100e+00, 3.059400e+00, 3.473200e+00, 5.532000e-01,\n","        2.679500e+01, 7.806000e-01, 3.680300e+00, 1.001300e+00,\n","        1.306900e+00, 1.347270e+01, 2.735200e+00, 1.472000e+00,\n","        3.619000e-01, 2.236000e-01, 2.161800e+00, 3.630600e+00,\n","        1.185100e+00, 6.031900e+00, 6.146000e-01, 4.236000e-01,\n","        2.631000e+00, 1.931500e+00, 2.633000e-01, 5.707000e-01,\n","        3.787000e-01, 8.769000e-01, 2.227600e+00, 4.832000e+00,\n","        7.943000e-01, 1.098400e+00, 1.935200e+00, 5.262000e-01,\n","        7.439200e+00, 4.788000e-01, 4.101000e-01, 1.725200e+00,\n","        2.668310e+01, 9.185600e+00, 5.027000e-01, 5.982000e-01,\n","        7.543000e-01, 1.693300e+01, 1.200500e+00, 1.151210e+01,\n","        6.555000e-01, 7.225000e-01, 1.946000e+00, 2.464500e+00,\n","        4.659000e-01, 3.546050e+01, 2.344800e+00, 1.574200e+00,\n","        3.982800e+00, 9.376000e-01, 5.604300e+00, 6.588000e-01,\n","        1.616100e+00, 1.689300e+00, 5.123000e-01, 6.593000e-01,\n","        3.858000e-01, 1.098000e+00, 4.780090e+01, 1.734900e+00,\n","        9.931300e+00, 3.581000e-01, 5.631000e-01, 3.258700e+00,\n","        1.425500e+00, 7.552600e+00, 4.626000e-01, 2.965200e+00,\n","        2.613000e+00, 4.442000e-01, 6.997800e+00, 4.597600e+00,\n","        3.437400e+00, 1.856900e+00, 3.043700e+00, 5.423000e-01,\n","        1.241400e+00, 3.252000e+00, 4.645000e-01, 1.196900e+00,\n","        6.172000e+00, 9.292000e-01, 3.829000e-01, 5.202600e+00,\n","        5.119300e+00, 3.252000e-01, 3.239900e+00, 6.668600e+00,\n","        5.103000e-01, 5.320100e+00, 7.517100e+00, 1.371800e+00,\n","        5.441000e+00, 1.936000e+00, 2.000510e+01, 2.210900e+00,\n","        9.283000e-01, 1.122200e+00, 1.636000e+00, 2.415600e+00,\n","        7.672000e-01, 7.097000e-01, 2.997000e+00, 1.082900e+01,\n","        1.288600e+00, 4.284000e+00, 4.899400e+00, 4.072100e+00,\n","        1.759600e+00, 6.585900e+00, 2.228100e+00, 7.932000e-01,\n","        9.571000e-01, 6.479200e+00, 6.010500e+00, 1.291600e+00,\n","        1.030770e+01, 3.272900e+00, 1.036930e+01, 5.403000e-01,\n","        3.193000e+00, 1.634900e+00, 7.844500e+00, 7.499000e-01,\n","        3.276600e+00, 9.224000e-01, 1.128200e+00, 1.323500e+00,\n","        1.446400e+00, 3.529000e-01, 3.385100e+00, 7.667000e-01,\n","        1.504762e+02, 2.247700e+00, 2.827000e+00, 3.001500e+00,\n","        6.076000e-01, 1.658740e+01, 4.294000e-01, 8.281000e-01,\n","        3.380500e+00, 2.251160e+01, 1.157160e+01, 6.297000e-01,\n","        2.102700e+00, 5.625400e+00, 2.674000e+00, 6.325000e-01,\n","        1.234324e+02, 1.233000e+00, 9.837300e+00, 6.433800e+00,\n","        9.510000e-02, 6.705800e+00, 4.925700e+00, 1.651270e+01,\n","        1.504500e+00, 8.564000e-01, 2.680000e-01, 5.263000e-01,\n","        6.085580e+01, 1.093600e+00, 3.023700e+00, 4.621000e-01,\n","        9.496000e-01, 2.352700e+00, 2.127200e+00, 2.060800e+00,\n","        6.767000e-01, 1.299300e+00, 3.974600e+00, 1.541800e+00,\n","        2.485100e+00, 8.415000e-01, 2.219590e+01, 3.687800e+00,\n","        2.522700e+00, 1.018900e+00, 1.068500e+00, 2.232400e+00,\n","        1.146750e+01, 3.472500e+00, 5.746000e-01, 7.737000e-01,\n","        2.750500e+00, 3.872300e+00, 9.443000e-01, 4.227100e+00,\n","        8.735000e-01, 8.171000e+00, 4.767000e+00, 2.008500e+00,\n","        5.911000e-01, 3.965300e+00, 5.910000e-01, 4.112000e-01,\n","        8.225000e-01, 1.173300e+00, 2.238700e+00, 4.619400e+00,\n","        1.467680e+01, 6.515000e-01, 1.524100e+00, 5.800000e-01,\n","        6.932000e-01, 4.874200e+00, 3.693000e-01, 8.785900e+00,\n","        6.186700e+00, 3.221500e+00, 7.002000e-01, 1.159600e+00,\n","        6.135000e-01, 3.100900e+00, 8.989000e-01, 1.572200e+00,\n","        9.625000e+00, 1.056210e+01, 4.967000e-01, 3.386900e+00,\n","        1.301200e+00, 3.433800e+00, 5.367000e-01, 2.660500e+00,\n","        2.805400e+00, 1.701700e+00, 1.030800e+00, 1.873800e+00,\n","        4.592000e-01, 3.684600e+00, 5.993700e+00, 1.304800e+00,\n","        1.387040e+01, 2.122660e+01, 5.208600e+01, 1.988000e-01,\n","        1.991600e+00, 7.022000e-01, 7.750900e+00, 6.407000e-01,\n","        7.129000e-01, 1.153830e+01, 2.014200e+00, 4.510400e+00,\n","        2.363100e+00, 3.429000e-01, 8.997000e-01, 1.697360e+01,\n","        1.062400e+00, 4.450000e+00, 1.141850e+01, 7.965000e-01,\n","        1.338000e+00, 1.009500e+00, 8.184000e-01, 3.139000e-01,\n","        3.350600e+00, 8.391000e+00, 2.476800e+00, 5.122000e-01,\n","        3.930100e+00, 1.861510e+01, 9.107000e-01, 1.129600e+00,\n","        5.503000e-01, 6.313200e+00, 3.007400e+00, 4.186000e+00,\n","        1.502200e+00, 5.095000e-01, 5.036000e-01, 5.697200e+00,\n","        1.051100e+00, 4.599000e-01, 1.438400e+00, 7.766400e+00,\n","        4.986100e+00, 2.536000e+00, 9.308000e-01, 1.523500e+00,\n","        4.168000e-01, 8.167000e-01, 6.455060e+01, 2.133200e+00,\n","        3.441270e+01, 5.385900e+00, 6.894300e+00, 1.131400e+00,\n","        1.808240e+01, 2.387000e-01, 1.542910e+01, 7.182800e+00,\n","        1.049700e+00, 4.502200e+00, 3.223400e+00, 1.680700e+00,\n","        1.261400e+00, 7.061000e-01, 1.878380e+01, 2.824700e+00,\n","        2.095213e+02, 1.793700e+00, 6.017600e+00, 5.996200e+00,\n","        6.883000e+00, 1.897000e+00, 1.093700e+00, 7.611000e-01,\n","        9.097500e+00, 4.514800e+00, 6.067100e+00, 9.555900e+00,\n","        1.832400e+00, 7.141000e-01, 9.563000e-01, 2.728100e+00,\n","        1.990400e+01, 5.231900e+00, 2.654000e+00, 8.226000e-01,\n","        1.290600e+01, 4.135000e-01, 4.444300e+00, 1.169700e+00,\n","        2.749000e+00, 5.902000e-01, 3.025000e-01, 1.301200e+00,\n","        5.621000e-01, 9.506200e+00, 1.011700e+00, 2.575800e+00,\n","        6.397000e-01, 5.249500e+00, 1.341000e+00, 3.699000e-01,\n","        2.459700e+00, 5.548000e-01, 1.884500e+00, 1.402360e+01,\n","        5.206100e+00, 2.035300e+00, 1.412800e+00, 1.457020e+01,\n","        5.572000e-01, 2.533400e+00, 2.242100e+00, 3.731300e+00,\n","        2.163600e+00, 1.104860e+01, 1.224700e+00, 3.011000e-01,\n","        1.744900e+00, 1.461900e+00, 2.347600e+00, 1.865200e+00,\n","        8.851900e+00, 7.496000e-01, 5.235770e+01, 1.319500e+00,\n","        9.200000e-01, 1.553600e+00, 1.257500e+01, 2.173700e+00,\n","        5.780000e-01, 2.962300e+00, 6.710900e+00, 3.553300e+00,\n","        1.932400e+00, 4.034900e+00, 8.445000e-01, 3.355000e+00,\n","        4.008800e+00, 7.942400e+00, 1.859700e+00, 5.834000e-01,\n","        4.254200e+00, 1.089100e+00, 3.989000e-01, 1.008450e+01,\n","        7.795500e+00, 3.711400e+00, 4.180600e+00, 1.175480e+01,\n","        8.727000e+00, 7.614000e-01, 2.315000e+00, 5.143000e-01,\n","        7.347000e-01, 2.018000e+01, 2.670300e+00, 4.152100e+00,\n","        7.099000e+00, 7.982000e-01, 6.948000e-01, 5.012300e+00,\n","        9.198000e-01, 2.836000e-01, 2.705400e+00, 1.302400e+00,\n","        1.433230e+01, 4.473000e-01, 1.774650e+01, 3.738000e-01,\n","        7.000000e-01, 6.121300e+00, 2.078820e+01, 1.271880e+01,\n","        3.880200e+00, 2.869260e+01, 1.723960e+01, 6.408000e-01,\n","        1.597300e+00, 3.905600e+00, 1.793700e+00, 1.843600e+00,\n","        1.448250e+01, 5.734800e+00, 5.275000e+00, 9.190800e+00,\n","        2.922100e+00, 6.205100e+00, 1.136610e+01, 1.646900e+00,\n","        7.742000e-01, 2.220100e+01, 7.507000e-01, 7.804000e+00,\n","        1.517320e+01, 1.228200e+00, 1.656200e+00, 3.715280e+01,\n","        6.707990e+01, 2.913660e+01, 3.039700e+00, 1.336700e+00,\n","        1.683700e+00, 4.457000e-01, 4.067930e+01, 1.442840e+01,\n","        5.671000e-01, 8.093000e-01, 1.168200e+00, 1.967200e+00,\n","        4.890300e+00, 1.652600e+00, 1.244300e+00, 7.952000e-01,\n","        7.367000e-01, 4.812000e-01, 4.278700e+00, 1.808452e+02,\n","        2.555900e+00, 5.948000e-01, 4.553000e+00, 7.325600e+00,\n","        2.455900e+00, 2.981200e+00, 1.670800e+00, 7.511700e+00,\n","        3.611900e+00, 2.068100e+00, 1.607300e+00, 1.157100e+00,\n","        6.841400e+00, 7.023400e+00, 4.415000e-01, 6.819000e-01,\n","        6.104100e+00, 5.296800e+00, 5.771300e+00, 8.584000e-01,\n","        4.480000e-01, 3.008800e+00, 3.407100e+00, 1.059370e+01,\n","        4.951000e-01, 7.108800e+00, 9.610000e-01, 2.792600e+00,\n","        1.198500e+00, 5.894200e+00, 2.228600e+00, 5.765200e+00,\n","        6.953000e-01, 7.948000e-01, 8.292000e-01, 4.900000e-01,\n","        3.470900e+00, 6.263800e+00, 2.035200e+00, 4.873000e-01]],\n","      dtype=float32)"]},"metadata":{"tags":[]},"execution_count":260}]},{"cell_type":"code","metadata":{"id":"v6ltOj6p3lXs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"0ea45e65-c402-4c4c-dccd-d5833eba1ec3","executionInfo":{"status":"ok","timestamp":1575196481855,"user_tz":-330,"elapsed":1230,"user":{"displayName":"kavyal jani","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBqIizcIpG2a-X_XfAmlPlYnzvTEj8gGdJbKNzlzw=s64","userId":"03855859549810352770"}}},"source":["train_x.shape"],"execution_count":134,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(700, 4)"]},"metadata":{"tags":[]},"execution_count":134}]},{"cell_type":"code","metadata":{"id":"qo_UQK7h3zsT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"1fc6209c-9510-4ffc-af0e-12242dc7b12e","executionInfo":{"status":"ok","timestamp":1575196481858,"user_tz":-330,"elapsed":763,"user":{"displayName":"kavyal jani","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBqIizcIpG2a-X_XfAmlPlYnzvTEj8gGdJbKNzlzw=s64","userId":"03855859549810352770"}}},"source":["test_y.shape"],"execution_count":135,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(300,)"]},"metadata":{"tags":[]},"execution_count":135}]},{"cell_type":"markdown","metadata":{"id":"vtedJXR-3x2V","colab_type":"text"},"source":[""]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"v6vE4eYCOB62"},"source":["## Building the Model in tensorflow"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"297_qja4OB7A"},"source":["1.Define Weights and Bias, use tf.zeros to initialize weights and Bias"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"L205qPeQOB7B","colab":{}},"source":["\n","W = tf.zeros(shape=(4,1))\n","B = tf.zeros(shape=(1))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"v2OudO6ZaPbs","colab_type":"code","colab":{}},"source":["w1 = tf.random_normal(shape=(4,5))\n","b1 = tf.zeros(shape=(5))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"HgtWA-UIOB7F"},"source":["2.Define a function to calculate prediction"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"JveGlx25OB7H","colab":{}},"source":["def prediction(x, w1, b1,w2,b2):\n","    \n","    xw_matmul = tf.matmul(x, w1)\n","    net1 = tf.add(xw_matmul, b1)\n","    y=tf.sigmoid(net1)\n","    net2=tf.matmul(y, w2)+b2\n","    out=tf.sigmoid(net2)\n","    return net2,out\n","  \n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"TL1hIwf_OB7M"},"source":["3.Loss (Cost) Function [Mean square error]"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"8VSWPiGXOB7P","colab":{}},"source":["def loss(predicted_y, desired_y):\n","  return tf.reduce_mean(tf.square(predicted_y - desired_y))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"jzG85FUlOB7U"},"source":["4.Function to train the Model\n","\n","1.   Record all the mathematical steps to calculate Loss\n","2.   Calculate Gradients of Loss w.r.t weights and bias\n","3.   Update Weights and Bias based on gradients and learning rate to minimize loss"]},{"cell_type":"code","metadata":{"id":"bDQxGUU4aaBY","colab_type":"code","colab":{}},"source":["def train(train_x, train_y, w1, b1,w2,b2, learning_rate=0.01):\n","    \n","    #Record mathematical operations on 'tape' to calculate loss\n","    with tf.GradientTape() as t:\n","        \n","        t.watch([w1,b1,w2,b2])\n","        \n","        net2,current_prediction = prediction(train_x, w1, b1,w2,b2)\n","        current_loss =loss(net2,train_y)\n","    \n","    #Calculate Gradients for Loss with respect to Weights and Bias\n","    dw1,db1,dw2,db2 = t.gradient(current_loss,[w1, b1,w2,b2])\n","    \n","    #Update Weights at output layer\n","    w2 = w2 - learning_rate*dw2\n","    b2 = b2 - learning_rate*db2\n","    \n","     #Update Weights at hidden layer\n","    w1 = w1 - learning_rate*dw1\n","    b1 = b1 - learning_rate*db1\n","    \n","    return w1, b1,w2,b2,current_loss"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Pdn749iC_K6G","colab_type":"text"},"source":[""]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"xSypb_u8OB7e"},"source":["## Train the model for 100 epochs \n","1. Observe the training loss at every iteration\n","2. Observe Train loss at every 5th iteration"]},{"cell_type":"code","metadata":{"id":"WQERzBuuYgJe","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":345},"outputId":"c2fa9b5c-3f1e-4d0c-c82c-ded809f5d25b","executionInfo":{"status":"error","timestamp":1575203071905,"user_tz":-330,"elapsed":1526,"user":{"displayName":"kavyal jani","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBqIizcIpG2a-X_XfAmlPlYnzvTEj8gGdJbKNzlzw=s64","userId":"03855859549810352770"}}},"source":["    for i in range(100):\n","        w1, b1,w2,b2,current_loss = train(train_x, train_y, W, B,w1,b1)\n","        print(\"Loss at step {:d}: {:.3f}\".format(i, current_loss))      #Training loss at each iteration"],"execution_count":274,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m\u001b[0m","\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)","\u001b[0;32m<ipython-input-274-a79638285f90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcurrent_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss at step {:d}: {:.3f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m      \u001b[0;31m#Training loss at each iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-271-df9bcdf8d9cc>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_x, train_y, w1, b1, w2, b2, learning_rate)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mnet2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcurrent_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mcurrent_loss\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-269-c5dd23329ec3>\u001b[0m in \u001b[0;36mprediction\u001b[0;34m(x, w1, b1, w2, b2)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mnet1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxw_matmul\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mnet2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnet2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/util/dispatch.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/math_ops.pyc\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[1;32m   2752\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2753\u001b[0m       return gen_math_ops.mat_mul(\n\u001b[0;32m-> 2754\u001b[0;31m           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[1;32m   2755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/gen_math_ops.pyc\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   6134\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m   6135\u001b[0m         \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6136\u001b[0;31m                   name=name)\n\u001b[0m\u001b[1;32m   6137\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6138\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/framework/op_def_library.pyc\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    792\u001b[0m         op = g.create_op(op_type_name, inputs, dtypes=None, name=scope,\n\u001b[1;32m    793\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m       \u001b[0;31m# Conditionally invoke tfdbg v2's op callback(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/util/deprecation.pyc\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/framework/ops.pyc\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3355\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input #%d is not a tensor: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3356\u001b[0m     return self._create_op_internal(op_type, inputs, dtypes, input_types, name,\n\u001b[0;32m-> 3357\u001b[0;31m                                     attrs, op_def, compute_device)\n\u001b[0m\u001b[1;32m   3358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3359\u001b[0m   def _create_op_internal(\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3424\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3425\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3426\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3427\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3428\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/framework/ops.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1768\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1769\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1770\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1771\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1608\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1609\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1610\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1612\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 1 and 4 for 'MatMul_621' (op: 'MatMul') with input shapes: [700,1], [4,5]."]}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"DOL2ncA1OB7q"},"source":["### Get the shapes and values of W and b"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ZGvtyTeuOB7r","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"bbeb0f47-b60d-42ab-e6e7-61ac9c82b8ea","executionInfo":{"status":"ok","timestamp":1575198729604,"user_tz":-330,"elapsed":1282,"user":{"displayName":"kavyal jani","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBqIizcIpG2a-X_XfAmlPlYnzvTEj8gGdJbKNzlzw=s64","userId":"03855859549810352770"}}},"source":["print(W)"],"execution_count":208,"outputs":[{"output_type":"stream","text":["Tensor(\"zeros_12:0\", shape=(4, 1), dtype=float32)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"vhDtOv5UOB7x","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"b044d011-7c54-45aa-b1c8-b8a7ad1f3e34","executionInfo":{"status":"ok","timestamp":1575198730202,"user_tz":-330,"elapsed":1385,"user":{"displayName":"kavyal jani","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBqIizcIpG2a-X_XfAmlPlYnzvTEj8gGdJbKNzlzw=s64","userId":"03855859549810352770"}}},"source":["B"],"execution_count":209,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor 'zeros_13:0' shape=(1,) dtype=float32>"]},"metadata":{"tags":[]},"execution_count":209}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ERq9GOKKciho"},"source":["### Model Prediction on 1st Examples in Test Dataset"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"gKGvUWahcihp","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"YJRBuqXhOB7_"},"source":["## Classification using tf.Keras\n","\n","In this exercise, we will build a Deep Neural Network using tf.Keras. We will use Iris Dataset for this exercise."]},{"cell_type":"code","metadata":{"id":"kU9_PKX-Fv7l","colab_type":"code","colab":{}},"source":["from keras.models import Sequential\n","from keras.layers import Dense\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"O0g6lorycihf"},"source":["### Load the given Iris data using pandas (Iris.csv)"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"6xFvb5sRcihg","colab":{}},"source":["data2 = pd.read_csv(\"/content/drive/My Drive/internalLab/iris.csv\", delimiter=\",\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6exkxDn0G2Ob","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":202},"outputId":"1a60c64a-2892-4dad-8ec5-62ce9fb039c9","executionInfo":{"status":"ok","timestamp":1575198742684,"user_tz":-330,"elapsed":2266,"user":{"displayName":"kavyal jani","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBqIizcIpG2a-X_XfAmlPlYnzvTEj8gGdJbKNzlzw=s64","userId":"03855859549810352770"}}},"source":["data2.head()"],"execution_count":212,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>SepalLengthCm</th>\n","      <th>SepalWidthCm</th>\n","      <th>PetalLengthCm</th>\n","      <th>PetalWidthCm</th>\n","      <th>Species</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>5.1</td>\n","      <td>3.5</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>4.9</td>\n","      <td>3.0</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>4.7</td>\n","      <td>3.2</td>\n","      <td>1.3</td>\n","      <td>0.2</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>4.6</td>\n","      <td>3.1</td>\n","      <td>1.5</td>\n","      <td>0.2</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>5.0</td>\n","      <td>3.6</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n","0   1            5.1           3.5            1.4           0.2  Iris-setosa\n","1   2            4.9           3.0            1.4           0.2  Iris-setosa\n","2   3            4.7           3.2            1.3           0.2  Iris-setosa\n","3   4            4.6           3.1            1.5           0.2  Iris-setosa\n","4   5            5.0           3.6            1.4           0.2  Iris-setosa"]},"metadata":{"tags":[]},"execution_count":212}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"SAB--Qdwcihm"},"source":["### Target set has different categories. So, Label encode them. And convert into one-hot vectors using get_dummies in pandas."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"IJr5dYnocihm","colab":{}},"source":["dummies = data2[\"Species\"].str.get_dummies(\" \") \n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"inMh_B7uG88v","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":202},"outputId":"b0d5c38e-1e04-44c5-d3a4-d50ab513bb66","executionInfo":{"status":"ok","timestamp":1575198745555,"user_tz":-330,"elapsed":882,"user":{"displayName":"kavyal jani","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBqIizcIpG2a-X_XfAmlPlYnzvTEj8gGdJbKNzlzw=s64","userId":"03855859549810352770"}}},"source":["dummies.head()"],"execution_count":214,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Iris-setosa</th>\n","      <th>Iris-versicolor</th>\n","      <th>Iris-virginica</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Iris-setosa  Iris-versicolor  Iris-virginica\n","0            1                0               0\n","1            1                0               0\n","2            1                0               0\n","3            1                0               0\n","4            1                0               0"]},"metadata":{"tags":[]},"execution_count":214}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"D95nY5ILcihj"},"source":["### Splitting the data into feature set and target set"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"RyMQoLMucihj","colab":{}},"source":["X_i = data2.iloc[:,0:5]\n","Y_i = dummies\n","train_x,test_x,train_y,test_y=train_test_split(X_i,Y_i,test_size=.30,random_state=2)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"b22qpC5xcihr"},"source":["###  Building Model in tf.keras\n","\n","Build a Linear Classifier model  <br>\n","1.  Use Dense Layer  with input shape of 4 (according to the feature set) and number of outputs set to 3<br> \n","2. Apply Softmax on Dense Layer outputs <br>\n","3. Use SGD as Optimizer\n","4. Use categorical_crossentropy as loss function "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Hov_UFnUciht","colab":{}},"source":["# Initialize Sequential model\n","model = tf.keras.models.Sequential()\n","\n","# Add Dense Layer which provides 10 Outputs after applying softmax\n","#model.add(tf.keras.layers.Dense(3,input=4, activation='softmax'))\n","\n","model.add(tf.keras.layers.Dense(3, input_shape=(5,),activation='softmax'))\n","# Comile the model\n","model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"T5FdzqIKcihw"},"source":["### Model Training "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"4qLEdHPscihx","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"f9bd15d3-617b-43b6-9a42-17fce8e49e9c","executionInfo":{"status":"ok","timestamp":1575201239455,"user_tz":-330,"elapsed":2935,"user":{"displayName":"kavyal jani","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBqIizcIpG2a-X_XfAmlPlYnzvTEj8gGdJbKNzlzw=s64","userId":"03855859549810352770"}}},"source":["model.fit(train_x, train_y, validation_data=(test_x, test_y), epochs=50,\n","          batch_size = train_x.shape[0])"],"execution_count":239,"outputs":[{"output_type":"stream","text":["Train on 105 samples, validate on 45 samples\n","Epoch 1/50\n","105/105 [==============================] - 0s 4ms/sample - loss: 1.1557 - acc: 0.3619 - val_loss: 12.4912 - val_acc: 0.2889\n","Epoch 2/50\n","105/105 [==============================] - 0s 65us/sample - loss: 10.6832 - acc: 0.3524 - val_loss: 10.9826 - val_acc: 0.3333\n","Epoch 3/50\n","105/105 [==============================] - 0s 31us/sample - loss: 12.1819 - acc: 0.3333 - val_loss: 22.8707 - val_acc: 0.2889\n","Epoch 4/50\n","105/105 [==============================] - 0s 40us/sample - loss: 19.9528 - acc: 0.3524 - val_loss: 7.7348 - val_acc: 0.2889\n","Epoch 5/50\n","105/105 [==============================] - 0s 38us/sample - loss: 7.0968 - acc: 0.2762 - val_loss: 19.1238 - val_acc: 0.2889\n","Epoch 6/50\n","105/105 [==============================] - 0s 44us/sample - loss: 16.3483 - acc: 0.3524 - val_loss: 16.0846 - val_acc: 0.3333\n","Epoch 7/50\n","105/105 [==============================] - 0s 36us/sample - loss: 16.2678 - acc: 0.3333 - val_loss: 29.4788 - val_acc: 0.2889\n","Epoch 8/50\n","105/105 [==============================] - 0s 42us/sample - loss: 25.6066 - acc: 0.3524 - val_loss: 10.2183 - val_acc: 0.2889\n","Epoch 9/50\n","105/105 [==============================] - 0s 40us/sample - loss: 8.5619 - acc: 0.3524 - val_loss: 18.5884 - val_acc: 0.3333\n","Epoch 10/50\n","105/105 [==============================] - 0s 39us/sample - loss: 20.2327 - acc: 0.3333 - val_loss: 21.1016 - val_acc: 0.2889\n","Epoch 11/50\n","105/105 [==============================] - 0s 35us/sample - loss: 18.2809 - acc: 0.3524 - val_loss: 2.3639 - val_acc: 0.3111\n","Epoch 12/50\n","105/105 [==============================] - 0s 35us/sample - loss: 1.8581 - acc: 0.4095 - val_loss: 12.4718 - val_acc: 0.3333\n","Epoch 13/50\n","105/105 [==============================] - 0s 37us/sample - loss: 14.2593 - acc: 0.3333 - val_loss: 19.4645 - val_acc: 0.3778\n","Epoch 14/50\n","105/105 [==============================] - 0s 36us/sample - loss: 16.9176 - acc: 0.3905 - val_loss: 13.8507 - val_acc: 0.3111\n","Epoch 15/50\n","105/105 [==============================] - 0s 37us/sample - loss: 13.9409 - acc: 0.2857 - val_loss: 16.5063 - val_acc: 0.2889\n","Epoch 16/50\n","105/105 [==============================] - 0s 39us/sample - loss: 14.0123 - acc: 0.3524 - val_loss: 17.0138 - val_acc: 0.3333\n","Epoch 17/50\n","105/105 [==============================] - 0s 32us/sample - loss: 17.6086 - acc: 0.3333 - val_loss: 26.9889 - val_acc: 0.2889\n","Epoch 18/50\n","105/105 [==============================] - 0s 38us/sample - loss: 23.3904 - acc: 0.3524 - val_loss: 7.8641 - val_acc: 0.2889\n","Epoch 19/50\n","105/105 [==============================] - 0s 34us/sample - loss: 6.4831 - acc: 0.3524 - val_loss: 18.6801 - val_acc: 0.3333\n","Epoch 20/50\n","105/105 [==============================] - 0s 36us/sample - loss: 20.6086 - acc: 0.3333 - val_loss: 19.2891 - val_acc: 0.2889\n","Epoch 21/50\n","105/105 [==============================] - 0s 37us/sample - loss: 16.6548 - acc: 0.3524 - val_loss: 1.0744 - val_acc: 0.4444\n","Epoch 22/50\n","105/105 [==============================] - 0s 39us/sample - loss: 0.8400 - acc: 0.5429 - val_loss: 3.5995 - val_acc: 0.4444\n","Epoch 23/50\n","105/105 [==============================] - 0s 40us/sample - loss: 4.1290 - acc: 0.4667 - val_loss: 20.4175 - val_acc: 0.2889\n","Epoch 24/50\n","105/105 [==============================] - 0s 33us/sample - loss: 17.6305 - acc: 0.3524 - val_loss: 1.8919 - val_acc: 0.3333\n","Epoch 25/50\n","105/105 [==============================] - 0s 32us/sample - loss: 1.4578 - acc: 0.4667 - val_loss: 9.7971 - val_acc: 0.3333\n","Epoch 26/50\n","105/105 [==============================] - 0s 63us/sample - loss: 11.2526 - acc: 0.3333 - val_loss: 20.9206 - val_acc: 0.4444\n","Epoch 27/50\n","105/105 [==============================] - 0s 66us/sample - loss: 18.1443 - acc: 0.4286 - val_loss: 12.7299 - val_acc: 0.3778\n","Epoch 28/50\n","105/105 [==============================] - 0s 43us/sample - loss: 12.5285 - acc: 0.3048 - val_loss: 17.9939 - val_acc: 0.2889\n","Epoch 29/50\n","105/105 [==============================] - 0s 43us/sample - loss: 15.2900 - acc: 0.3524 - val_loss: 14.4991 - val_acc: 0.3333\n","Epoch 30/50\n","105/105 [==============================] - 0s 40us/sample - loss: 14.7622 - acc: 0.3333 - val_loss: 28.4294 - val_acc: 0.2889\n","Epoch 31/50\n","105/105 [==============================] - 0s 76us/sample - loss: 24.6267 - acc: 0.3524 - val_loss: 9.2705 - val_acc: 0.2889\n","Epoch 32/50\n","105/105 [==============================] - 0s 43us/sample - loss: 7.6726 - acc: 0.3524 - val_loss: 16.7226 - val_acc: 0.3333\n","Epoch 33/50\n","105/105 [==============================] - 0s 36us/sample - loss: 18.4007 - acc: 0.3333 - val_loss: 20.3542 - val_acc: 0.3778\n","Epoch 34/50\n","105/105 [==============================] - 0s 35us/sample - loss: 17.5428 - acc: 0.3810 - val_loss: 1.8046 - val_acc: 0.3556\n","Epoch 35/50\n","105/105 [==============================] - 0s 51us/sample - loss: 1.3173 - acc: 0.4000 - val_loss: 13.3861 - val_acc: 0.3333\n","Epoch 36/50\n","105/105 [==============================] - 0s 48us/sample - loss: 15.4981 - acc: 0.3333 - val_loss: 17.5387 - val_acc: 0.4667\n","Epoch 37/50\n","105/105 [==============================] - 0s 56us/sample - loss: 15.1447 - acc: 0.5048 - val_loss: 12.8494 - val_acc: 0.3778\n","Epoch 38/50\n","105/105 [==============================] - 0s 48us/sample - loss: 13.0636 - acc: 0.3143 - val_loss: 15.1979 - val_acc: 0.2889\n","Epoch 39/50\n","105/105 [==============================] - 0s 75us/sample - loss: 12.7755 - acc: 0.3524 - val_loss: 17.2373 - val_acc: 0.3333\n","Epoch 40/50\n","105/105 [==============================] - 0s 39us/sample - loss: 17.9655 - acc: 0.3333 - val_loss: 25.8983 - val_acc: 0.2889\n","Epoch 41/50\n","105/105 [==============================] - 0s 80us/sample - loss: 22.3410 - acc: 0.3524 - val_loss: 6.9523 - val_acc: 0.2889\n","Epoch 42/50\n","105/105 [==============================] - 0s 89us/sample - loss: 5.6254 - acc: 0.3524 - val_loss: 17.9292 - val_acc: 0.3333\n","Epoch 43/50\n","105/105 [==============================] - 0s 34us/sample - loss: 19.8379 - acc: 0.3333 - val_loss: 19.0582 - val_acc: 0.3778\n","Epoch 44/50\n","105/105 [==============================] - 0s 38us/sample - loss: 16.3451 - acc: 0.4190 - val_loss: 1.0063 - val_acc: 0.4444\n","Epoch 45/50\n","105/105 [==============================] - 0s 67us/sample - loss: 0.7201 - acc: 0.5524 - val_loss: 6.6126 - val_acc: 0.3778\n","Epoch 46/50\n","105/105 [==============================] - 0s 62us/sample - loss: 7.7033 - acc: 0.3619 - val_loss: 22.1330 - val_acc: 0.4444\n","Epoch 47/50\n","105/105 [==============================] - 0s 69us/sample - loss: 19.1154 - acc: 0.4762 - val_loss: 10.8725 - val_acc: 0.3778\n","Epoch 48/50\n","105/105 [==============================] - 0s 47us/sample - loss: 10.3518 - acc: 0.3143 - val_loss: 19.2459 - val_acc: 0.2889\n","Epoch 49/50\n","105/105 [==============================] - 0s 45us/sample - loss: 16.3245 - acc: 0.3524 - val_loss: 12.0881 - val_acc: 0.3333\n","Epoch 50/50\n","105/105 [==============================] - 0s 55us/sample - loss: 12.0323 - acc: 0.3333 - val_loss: 29.7044 - val_acc: 0.3111\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f5aeb59efd0>"]},"metadata":{"tags":[]},"execution_count":239}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"y-SgSSdRcih5"},"source":["### Model Prediction"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"GBgKZkhkcih6","colab":{"base_uri":"https://localhost:8080/","height":797},"outputId":"5a4796fd-0b11-49de-c058-0e747a6e1925","executionInfo":{"status":"ok","timestamp":1575201329364,"user_tz":-330,"elapsed":1065,"user":{"displayName":"kavyal jani","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBqIizcIpG2a-X_XfAmlPlYnzvTEj8gGdJbKNzlzw=s64","userId":"03855859549810352770"}}},"source":["model.predict(test_x)"],"execution_count":240,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[2.00499490e-01, 3.81500155e-01, 4.18000370e-01],\n","       [4.07079279e-01, 5.34139514e-01, 5.87812141e-02],\n","       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n","       [6.19137252e-04, 2.04135827e-03, 9.97339547e-01],\n","       [2.06249062e-09, 9.93805287e-08, 9.99999881e-01],\n","       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n","       [7.72290176e-10, 1.96811101e-08, 1.00000000e+00],\n","       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n","       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n","       [6.55504963e-19, 2.50469442e-16, 1.00000000e+00],\n","       [7.83044323e-20, 4.48211256e-17, 1.00000000e+00],\n","       [1.37002624e-17, 4.18137984e-15, 1.00000000e+00],\n","       [4.00301333e-14, 2.35428517e-12, 1.00000000e+00],\n","       [3.37551743e-01, 5.71200252e-01, 9.12479907e-02],\n","       [1.62055011e-37, 1.61553775e-30, 1.00000000e+00],\n","       [1.50679438e-23, 1.14455947e-18, 1.00000000e+00],\n","       [1.76572372e-17, 3.28670086e-15, 1.00000000e+00],\n","       [0.00000000e+00, 2.51135787e-35, 1.00000000e+00],\n","       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n","       [0.00000000e+00, 7.11338064e-33, 1.00000000e+00],\n","       [5.58588854e-34, 2.06037257e-27, 1.00000000e+00],\n","       [1.44071850e-32, 1.27832475e-26, 1.00000000e+00],\n","       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n","       [0.00000000e+00, 1.15745442e-34, 1.00000000e+00],\n","       [0.00000000e+00, 4.60486805e-32, 1.00000000e+00],\n","       [1.09775132e-11, 6.71443345e-10, 1.00000000e+00],\n","       [5.51569462e-01, 4.29697692e-01, 1.87327862e-02],\n","       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n","       [3.60577955e-18, 2.79112179e-15, 1.00000000e+00],\n","       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n","       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n","       [1.01587316e-08, 2.41272403e-07, 9.99999762e-01],\n","       [5.14554555e-28, 6.50437210e-23, 1.00000000e+00],\n","       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n","       [1.67344677e-37, 2.03206636e-30, 1.00000000e+00],\n","       [6.92416099e-04, 1.36558036e-03, 9.97942030e-01],\n","       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n","       [0.00000000e+00, 3.81988424e-33, 1.00000000e+00],\n","       [1.70268669e-23, 7.71607879e-19, 1.00000000e+00],\n","       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n","       [1.39314540e-34, 4.29891975e-28, 1.00000000e+00],\n","       [0.00000000e+00, 1.13605000e-35, 1.00000000e+00],\n","       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n","       [0.00000000e+00, 7.17545572e-35, 1.00000000e+00],\n","       [2.30079331e-03, 1.04958396e-02, 9.87203419e-01]], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":240}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"P32ASP1Vjt0a"},"source":["### Save the Model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"n8rd0jjAjyTR","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"XiipRpe7rbVh"},"source":["### Build and Train a Deep Neural network with 2 hidden layer  - Optional - For Practice\n","\n","Does it perform better than Linear Classifier? What could be the reason for difference in performance?"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"v5Du3lubr4sA","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}